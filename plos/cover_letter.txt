# Cover letter
## Reinforcement Learning Produces Dominant Strategies for the Iterated Prisoner's Dilemma

To the editors,

This paper presents a numerical study of novel strategies for the iterated
Prisoner's dilemma.

We feel that this paper presents a strong contribution to the literature as it
not only presents one of the largest Prisoner's Dilemma tournament (made
possible using an open source library with over 40 contributors) but also
describes the use of a number of strategy archetypes. Whilst some of these
archetypes are not in themselves novel (finite state machines for example),
others are (neural networks for example). Furthermore, it is the effective
training of these strategies using reinforcement learning that is a particularly
strong contribution.

A number of results and in depth analysis are presented, not only for standard
tournaments but also for noisy tournaments.

This paper not only offers a good piece of reference text (all strategies are
fully referenced) but offers many insights as to the effectiveness of
reinforcement learning.

Thank you for taking the time to consider our work,

The Authors.

ADDENDUM:

Following the first review, we have been asked to include a Competing Interests
Statement that clarifies the position Google Inc. (the employer of one of the
authors):

The funder (Google Inc.)  provided support in the form of salaries for the
author MH, but did not have any additional role in the study
design, data collection and analysis, decision to publish, or
preparation of the manuscript. The specific roles of this author is
articulated in the 'author contributions' section. This does not alter our
adherence to PLOS ONE policies on sharing data and materials.

Furthermore, we have documentation that the project is
officially separate from Google Inc and any IP claims. This documentation can 
produced upon request.
